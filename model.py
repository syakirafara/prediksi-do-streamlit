# -*- coding: utf-8 -*-
"""92.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xZlBkcwldUyOyiKQ3OxOnUJmAZKOQ_zX
"""

import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('data.csv', sep=';')

# Clean column names
df.columns = df.columns.str.lower().str.strip()

# Normalize target text FIRST
df['target'] = df['target'].str.lower().str.strip()

# Keep only Graduate & Dropout
df = df[df['target'].isin(['graduate', 'dropout'])]

selected_features = [
    'marital status',
    'application mode',
    'application order',
    'course',
    'daytime/evening attendance',
    'previous qualification',
    'previous qualification (grade)',
    'nacionality',
    "mother's qualification",
    "father's qualification",
    "mother's occupation",
    "father's occupation",
    'admission grade',
    'debtor',
    'tuition fees up to date',
    'gender',
    'age at enrollment',

    # Academic â€“ 1st semester
    'curricular units 1st sem (enrolled)',
    'curricular units 1st sem (evaluations)',
    'curricular units 1st sem (approved)',
    'curricular units 1st sem (grade)',

    # Academic â€“ 2nd semester
    'curricular units 2nd sem (enrolled)',
    'curricular units 2nd sem (evaluations)',
    'curricular units 2nd sem (approved)',
    'curricular units 2nd sem (grade)',

    # Target
    'target'
]

df = df[selected_features]

# Normalize target text
df['target'] = df['target'].str.lower().str.strip()

df['target'] = df['target'].map({
    'graduate': 0,
    'dropout': 1
})


# Check
df['target'].value_counts()

df.isnull().sum()
df.dropna(inplace=True)

df = pd.get_dummies(df, drop_first=True)

from sklearn.model_selection import train_test_split

X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score

pipeline = Pipeline([
    ('model', XGBClassifier(
        objective='binary:logistic',
        n_estimators=300,
        max_depth=6,
        learning_rate=0.08,
        subsample=0.8,
        colsample_bytree=0.8,
        gamma=0.1,
        min_child_weight=4,
        eval_metric='logloss',
        random_state=42
    ))
])

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    confusion_matrix
)

# Accuracy
acc = accuracy_score(y_test, y_pred)

# Precision, Recall, F1
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("ðŸ“Š Evaluation Metrics")
print(f"Accuracy : {acc:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall   : {recall:.4f}")
print(f"F1 Score : {f1:.4f}")

print("\nðŸ§¾ Classification Report")
print(classification_report(y_test, y_pred, target_names=['Graduate', 'Dropout']))

print("\nðŸ§© Confusion Matrix")
print(confusion_matrix(y_test, y_pred))

from sklearn.metrics import classification_report

y_pred = pipeline.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

scores = cross_val_score(
    pipeline,
    X_train,
    y_train,
    cv=cv,
    scoring='accuracy'
)

print("REAL CV Accuracy:", scores.mean())

df.head()

import joblib

joblib.dump(pipeline, "xgb_dropout_model.pkl")
print("âœ… Model saved as xgb_dropout_model.pkl")